---
version: '3.7'
services:
  ## MySQL Docker Compose Config
  postgres-order:
    container_name: postgres-order
    image: postgres
    environment:
      PGUSER: orderUser
      POSTGRES_DB: order_service
      POSTGRES_USER: orderUser
      POSTGRES_PASSWORD: password
      PGDATA: /data/postgres
    volumes:
      - ./postgres-order:/data/postgres
    expose:
      - "5431"
    ports:
      - "5431:5431"
    command: -p 5431
    restart: always
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d postgres -U orderUser -p 5431" ]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  postgres-inventory:
    container_name: postgres-inventory
    image: postgres
    environment:
      POSTGRES_DB: inventory_service
      POSTGRES_USER: inventoryUser
      POSTGRES_PASSWORD: password
      PGDATA: /data/postgres
    volumes:
      - ./postgres-inventory:/data/postgres
    ports:
      - "5432:5432"
    restart: always
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d postgres -U inventoryUser -p 5432" ]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  ## Mongo Docker Compose Config
  mongodb:
    container_name: mongodb
    image: mongo:6-jammy
    restart: always
    ports:
      - "27017:27017"
    expose:
      - "27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      timeout: 10s
      retries: 3
      interval: 60s
      start_period: 30s

  ## Keycloak Config with Mysql database
  keycloak-mysqldb:
    container_name: keycloak-mysqldb
    image: mysql:5.7
    volumes:
      - ./mysql_keycloak_data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: "password"
      MYSQL_DATABASE: "keycloak"
      MYSQL_USER: "keycloak"
      MYSQL_PASSWORD: "password"
    healthcheck:
      test: mysqladmin ping -h 127.0.0.1 -u $$MYSQL_USER --password=$$MYSQL_PASSWORD
      timeout: 20s
      retries: 3
      start_period: 30s
      interval: 60s

  keycloak:
    container_name: keycloak
    image: quay.io/keycloak/keycloak:23.0.4
    command: [ "start-dev", "--import-realm","--http-port=8181" ]
    environment:
      DB_VENDOR: MYSQL
      DB_ADDR: mysql
      DB_DATABASE: keycloak
      DB_USER: keycloak
      DB_PASSWORD: password
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports:
      - "8181:8181"
    volumes:
      - ./realms/:/opt/keycloak/data/import/
    depends_on:
      - keycloak-mysqldb
  #    healthcheck:
  #      test: wget --no-verbose --tries=1 --spider http://localhost:8181 || exit 1
  #      interval: 30s
  #      timeout: 5s
  #      retries: 3

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
    healthcheck:
      test: nc -z localhost 2181 || exit -1
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  kafka:
    image: confluentinc/cp-kafka:7.3.2
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      zookeeper:
        condition: service_healthy
  
  ## Zipkin
  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    ports:
      - "9411:9411"
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:9411/health || exit 1
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 30s

  prometheus:
    image: prom/prometheus:v2.37.1
    container_name: prometheus
    restart: always
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - product-service
      - inventory-service
      - order-service
      - notification-service
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:9090 || exit 1
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 30s

  grafana:
    image: grafana/grafana-oss:8.5.2
    container_name: grafana
    restart: always
    ports:
      - "3000:3000"
    links:
      - prometheus:prometheus
    volumes:
      - ./Grafana_Dashboard.json:/var/lib/grafana/Grafana_Dashboard.json
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=password
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 40s

  elasticsearch:
    hostname: elasticsearch
    container_name: elasticsearch
    image: elasticsearch:7.6.1
    volumes:
      - elasticsearch:/usr/share/elasticsearch/data
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_USER: "elastic"
      ELASTIC_PASSWORD: "changeme"
      discovery.type: single-node
      xpack.security.enabled: "true"
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test: "curl http://$ELASTIC_USER:$ELASTIC_PASSWORD@localhost:9200/_cat/health"
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  logstash:
    hostname: logstash
    container_name: logstash
    image: logstash:7.6.1
    ports:
      - "5000:5000"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_USER: "elastic"
      ELASTIC_PASSWORD: "changeme"
      XPACK_MONITORING_ELASTICSEARCH_USERNAME: "elastic"
      XPACK_MONITORING_ELASTICSEARCH_PASSWORD: "changeme"
      XPACK_MONITORING_ELASTICSEARCH_HOSTS: "elasticsearch:9200"
      XPACK_MONITORING_ENABLED: "true"
    volumes:
      - ./elasticsearch-kibana/logstash/pipeline:/usr/share/logstash/pipeline:ro
    restart: unless-stopped
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: "curl http://$ELASTIC_USER:$ELASTIC_PASSWORD@localhost:9600/_cat/health"
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 30s

  kibana:
    hostname: kibana
    container_name: kibana
    image: kibana:7.6.1
    environment:
      ELASTIC_USER: "elastic"
      ELASTIC_PASSWORD: "changeme"
      ELASTICSEARCH_USERNAME: "elastic"
      ELASTICSEARCH_PASSWORD: "changeme"
      # Because Elasticsearch is running in a containerized environment
      # (setting this to false will result in CPU stats not being correct in the Monitoring UI):
      XPACK_MONITORING_UI_CONTAINER_ELASTICSEARCH_ENABLED: "true"
    ports:
      - "5601:5601"
    restart: unless-stopped
    depends_on:
      elasticsearch:
        condition: service_healthy
      logstash:
        condition: service_healthy
    healthcheck:
      test: curl http://localhost:5601
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 30s

  ## Eureka Server
  discovery-server:
    build: discovery-server
    container_name: discovery-server
    environment:
      #logstash
      logstash.host: "logstash"
      logstash.port: "5000"
    ports:
      - "8761:8761"
    healthcheck:
      test: curl http://localhost:8761
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 30s
    depends_on:
      zipkin:
        condition: service_healthy
      kibana:
        condition: service_healthy
      logstash:
        condition: service_healthy
  api-gateway:
    build: api-gateway
    container_name: api-gateway
    ports:
      - "8282:8282"
    expose:
      - "8282"
    environment:
      #logstash
      logstash.host: "logstash"
      logstash.port: "5000"
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_SECURITY: TRACE
    depends_on:
      zipkin:
        condition: service_healthy
      kibana:
        condition: service_healthy
      logstash:
        condition: service_healthy
      discovery-server:
        condition: service_healthy
    healthcheck:
      test: curl http://localhost:8282/actuator/health
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 30s

  product-service:
    container_name: product-service
    build: product-service
    environment:
      #logstash
      logstash.host: "logstash"
      logstash.port: "5000"
    depends_on:
      mongodb:
        condition: service_healthy
      discovery-server:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      logstash:
        condition: service_healthy
      zipkin:
        condition: service_healthy
    healthcheck:
      test: curl http://product-service:8991/actuator/health
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 40s

  order-service:
    container_name: order-service
    build: order-service
    environment:
      #logstash
      logstash.host: "logstash"
      logstash.port: "5000"
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres-order:5431/order_service
    depends_on:
      postgres-order:
        condition: service_healthy
      discovery-server:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      logstash:
        condition: service_healthy
      zipkin:
        condition: service_healthy
    healthcheck:
      test: curl http://order-service:8992/actuator/health
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 40s

  inventory-service:
    container_name: inventory-service
    build: inventory-service
    environment:
      #logstash
      logstash.host: "logstash"
      logstash.port: "5000"
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres-inventory:5432/inventory_service
    depends_on:
      postgres-inventory:
        condition: service_healthy
      discovery-server:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      kibana:
        condition: service_healthy
      zipkin:
        condition: service_healthy
    healthcheck:
      test: curl http://inventory-service:8994/actuator/health
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 30s

  notification-service:
    container_name: notification-service
    build: notification-service
    environment:
      #logstash
      logstash.host: "logstash"
      logstash.port: "5000"
    depends_on:
      zipkin:
        condition: service_healthy
      discovery-server:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      kibana:
        condition: service_healthy
    healthcheck:
      test: curl http://notification-service:8993/actuator/health
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 60s

volumes:
  elasticsearch:
  mongo-data:
networks:
  internal:
